-- | Draft for API of new DSL.
--
--   If our actors only deliver single result and then terminate they
--   look very like a simple function call. This means that we can to
--   a degree pretend that we write simple imperative
--   program. Furthermore we can write programs as if we write
--   non-concurrent program and let DSL compiler handle all
--   synchronization.
--
--   Missing parts
--
--    * Scheduling is non-existent. No way to say what part of
--      computation resources we need to devote to actor
--
--    * How do we represent foreign kernels? What are types
--      corresponding to scalars/arrays etc? How do we specify data
--      layout?
--
--    * How do we wrap kernels?
--
--    * Explicit parallelism. Do we need it? In what form?
--
module NewDSL where


----------------------------------------------------------------
-- Basic data types
----------------------------------------------------------------

-- | Monad for distributed computation.
--
--   Since CAD is same for whole program it's threaded implicitly.
data Comp a


-- | Value obtained during computation.
--
--   It could be plain value or result generated by another
--   actor. Both are treated the same way and not distinguishable by
--   user. Ensuring that we already received value at the point we
--   need it is job of compiler.
--
--   We can pass such values to actors which are executed
--   elsewhere. It's not entirely clear how to implement such message
--   passing.
data Value a


-- | Type wrapper for value computed by kernel
data Kernel a



----------------------------------------------------------------
-- Async computations
----------------------------------------------------------------

-- | Tell compiler that value should be received by this point in
--   computation.
expect :: Value a -> Comp ()
expect = undefined


-- | Compute value generated by kernel. It's done in the same thread
--   no new actors are forked.
--
--   Kernel that takes two parameters have type:
--
--   > Value a -> Value b -> Comp (Kernel c)
--
--   So we pass parameters to the kernel using normal function
--   application.
eval :: Comp (Kernel a) -> Comp (Value a)
eval = undefined

-- | Compute value using separate actor. Otherwise it's same as eval.
async :: Comp (Kernel a) -> Comp (Value a)
async = undefined



----------------------------------------------------------------
-- Collective operations
--
-- Finding right way to perform same computation on several nodes is
-- difficult.
--
-- Below is solution specific to map-reduce. It is very important but
-- it's a special case. We need other problems if we want to find more
-- generic solution.
----------------------------------------------------------------


-- | This data type is akin to the Value data type but instead it
--   represent collection of values of type a. It contains information
--   about actors which performing computation and information about
--   how to synchronize values.
data Set a


-- | Collect values from set. 
--
--   Here we pass reduce function and initial value as parameter. It's
--   not clear whether it's possible or desirable.
gather :: Set a -> Value (a -> a -> a) -> Value a -> Comp (Value a)
gather = undefined


-- | Deeply magical data type. It represent set of values to be sent
--   to the workers in map-reduce.
data Scatter a


-- | Send same value to all destination
same :: Value a -> Scatter a
same = undefined

{-
-- | Spawn computations for every worker node.
scatter :: Process (Kernel a) -> Process 
scatter = undefined
-}
